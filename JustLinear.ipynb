{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run just the linear regression, as a benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run just the linear regression, against each of the created pre-processed data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's take care of the imports/functions to get running..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_cats.csv\n",
      "data_conts.csv\n",
      "data_new.csv\n",
      "data_orig_only.csv\n",
      "test.csv\n",
      "test.csv.zip\n",
      "test_data_cats.csv\n",
      "test_data_conts.csv\n",
      "test_data_data_new.csv\n",
      "test_data_orig_only.csv\n",
      "train.csv\n",
      "train.csv.zip\n",
      "\n",
      "clusters_cat.npy\n",
      "clusters_cat.npy_01.npy\n",
      "clusters_cat.npy_02.npy\n",
      "clusters_cont.npy\n",
      "clusters_cont.npy_01.npy\n",
      "clusters_cont.npy_02.npy\n",
      "clusters.npy\n",
      "clusters.npy_01.npy\n",
      "clusters.npy_02.npy\n",
      "grid_L2_KNN.pkl\n",
      "grid_L2_Lin.pkl\n",
      "grid_regr0.pkl\n",
      "grid_regr1.pkl\n",
      "grid_regr2.pkl\n",
      "grid_regr3.pkl\n",
      "MAE_tracking.npy\n",
      "oldmodels\n",
      "x_layer2.npy\n",
      "x_layer2.npy_01.npy\n",
      "x_layer2_w_clusters.npy\n",
      "x_layer2_w_clusters.npy_01.npy\n",
      "\n",
      "result_submission_orig_only_linear.csv\n",
      "result_submission_stack_linear.csv\n",
      "result_submission_stack_xgb.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os,sys,time,random,math,time\n",
    "import tarfile, zipfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from subprocess import check_output\n",
    "datadir=\"./input/\"\n",
    "cachedir=\"./cache/\"\n",
    "outdir='./output/'\n",
    "\n",
    "print(check_output([\"ls\", datadir]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", cachedir]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", outdir]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(datadir,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    #data = pd.read_csv(filename)\n",
    "    data = ''\n",
    "    print (\"loading: \"+datadir+filename)\n",
    "    try:\n",
    "        if zipfile.is_zipfile(datadir+filename):\n",
    "            z = zipfile.ZipFile(datadir+filename)\n",
    "            filename = z.open(filename[:-4])\n",
    "        else:\n",
    "            filename=datadir+filename\n",
    "        data = pd.read_csv(filename, parse_dates=True)  \n",
    "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
    "        print(e)\n",
    "    return data\n",
    "\n",
    "def writeData(data,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    try:\n",
    "        data.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be written.\")\n",
    "        print(e)\n",
    "    verify=[]\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                verify.append(line)\n",
    "        f.closed\n",
    "        return verify[:5]\n",
    "    except IOError:\n",
    "        sys.std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_wrapper(x,y,regr,param,regr_name='BLANK'):\n",
    "    start_time = time.time()\n",
    "    print(\"In:{}\".format(regr))\n",
    "    filename= 'grid_{}.pkl'.format(regr_name)\n",
    "    if os.path.isfile(cachedir+filename):\n",
    "        print filename,\" exists, importing \"\n",
    "        return joblib.load(cachedir+filename) \n",
    "    else:\n",
    "        print(\"{} not present, running a gridsearch\".format(filename))\n",
    "        #search the param_grid for best params based on the f1 score\n",
    "        grid_search = GridSearchCV(regr,\n",
    "                                   param_grid= param,\n",
    "                                   n_jobs= -1,\n",
    "                                   scoring=make_scorer(mean_absolute_error,greater_is_better=False)) \n",
    "        print(\"debug 1\")\n",
    "        grid_search.fit(x,y)\n",
    "        print \"debug2\"\n",
    "        #reach into the grid search and pull out the best parameters, and set those on the clf\n",
    "        params={}\n",
    "        for p in grid_search.best_params_:\n",
    "            params[p]=grid_search.best_params_[p]\n",
    "        regr.set_params(**params)\n",
    "        print(\"run time:{}s\".format(round((time.time()-start_time), 3) ))   \n",
    "        joblib.dump(regr,cachedir+filename) \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/data_orig_only.csv\n",
      "Dataset has 188318 samples with 132 features each.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188318 entries, 0 to 188317\n",
      "Columns: 132 entries, id to loss\n",
      "dtypes: float64(131), int64(1)\n",
      "memory usage: 189.7 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202349</td>\n",
       "      <td>-0.953493</td>\n",
       "      <td>0.296826</td>\n",
       "      <td>-0.255633</td>\n",
       "      <td>0.916140</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.761787</td>\n",
       "      <td>-0.070392</td>\n",
       "      <td>0.984628</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629320</td>\n",
       "      <td>-0.704206</td>\n",
       "      <td>0.698552</td>\n",
       "      <td>-0.792214</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.560798</td>\n",
       "      <td>0.585682</td>\n",
       "      <td>-0.330645</td>\n",
       "      <td>0.343682</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9   ...     \\\n",
       "0   1   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   ...      \n",
       "1   2   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   ...      \n",
       "\n",
       "      cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
       "0 -0.202349 -0.953493  0.296826 -0.255633  0.916140  0.744792  0.761787   \n",
       "1 -0.629320 -0.704206  0.698552 -0.792214  0.664384  0.560798  0.585682   \n",
       "\n",
       "     cont13    cont14     loss  \n",
       "0 -0.070392  0.984628  2213.18  \n",
       "1 -0.330645  0.343682  1283.60  \n",
       "\n",
       "[2 rows x 132 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/test_data_orig_only.csv\n",
      "Dataset has 125546 samples with 132 features each.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125546 entries, 0 to 125545\n",
      "Columns: 132 entries, id to loss\n",
      "dtypes: float64(131), int64(1)\n",
      "memory usage: 126.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577920</td>\n",
       "      <td>-1.003169</td>\n",
       "      <td>0.709425</td>\n",
       "      <td>-0.809264</td>\n",
       "      <td>0.618125</td>\n",
       "      <td>0.596157</td>\n",
       "      <td>0.588824</td>\n",
       "      <td>-0.208032</td>\n",
       "      <td>0.679093</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549657</td>\n",
       "      <td>-0.688733</td>\n",
       "      <td>0.799188</td>\n",
       "      <td>-0.476006</td>\n",
       "      <td>0.779139</td>\n",
       "      <td>0.823734</td>\n",
       "      <td>0.815239</td>\n",
       "      <td>-0.582283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  ...      cont6  \\\n",
       "0   4   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...  -0.577920   \n",
       "1   6   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0  ...  -0.549657   \n",
       "\n",
       "      cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
       "0 -1.003169  0.709425 -0.809264  0.618125  0.596157  0.588824 -0.208032   \n",
       "1 -0.688733  0.799188 -0.476006  0.779139  0.823734  0.815239 -0.582283   \n",
       "\n",
       "     cont14  loss  \n",
       "0  0.679093   0.0  \n",
       "1  0.000000   0.0  \n",
       "\n",
       "[2 rows x 132 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "### and now, let's import the data\n",
    "data = loadData(datadir,'data_orig_only.csv')\n",
    "display(data.info())\n",
    "display(data.head(2))\n",
    "\n",
    "test_data= loadData(datadir,'test_data_orig_only.csv') \n",
    "display(test_data.info())\n",
    "display(test_data.head(2))\n",
    "# we don't want the ID columns in X\n",
    "x=data.drop(['id','loss'],1).values\n",
    "# loss is our label\n",
    "#y=data['loss'].values\n",
    "shift=200\n",
    "y = np.log(data['loss']+shift).ravel()\n",
    "\n",
    "x_test_data=test_data.drop(['loss','id'],1) .values# didn't have the loss column before, make it go away! don't need ID!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a simple LinearRegression to get started---remove this later?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up the data first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample train data size:150654'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:4.859s\n",
      "Mean abs error: 1277.38\n",
      "predict time:0.011s\n",
      "final predict time:0.100368022919\n",
      "final sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1388.18340489\\n',\n",
       " '6,1816.85725276\\n',\n",
       " '9,12518.9310425\\n',\n",
       " '12,4567.29277982\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  train/validation split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split( x,\n",
    "                                                                y,\n",
    "                                                               test_size=0.20,\n",
    "                                                                random_state=42)\n",
    "display(\"sample train data size:{}\".format(len(y_train)))\n",
    "stat_tracking=[]\n",
    "estimator=LinearRegression(n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "estimator.fit(X_train,y_train)\n",
    "fit_time=time.time()-start_time\n",
    "\n",
    "start_time = time.time()\n",
    "curr_predict=np.array(estimator.predict(X_validation)).copy()\n",
    "predict_time=time.time()-start_time\n",
    "\n",
    "#track the run info\n",
    "MAE=np.mean(abs(np.exp(curr_predict) - np.exp(y_validation)))\n",
    "stat_tracking.append([\"run:{}\".format('BASE'),MAE,start_time,predict_time])\n",
    "\n",
    "#show some stats on that last regressions run\n",
    "print(\"\\nfit time:{}s\".format(round(fit_time, 3) ))\n",
    "print(\"Mean abs error: {:.2f}\".format(MAE))\n",
    "print(\"predict time:{}s\".format(round(predict_time, 3) ))\n",
    "\n",
    "\n",
    "#the Final Prediction on the test data\n",
    "start_time = time.time()\n",
    "test_data['loss']=np.exp(estimator.predict(x_test_data))-200\n",
    "final_predict_time=time.time()-start_time\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_orig_only_linear.csv\"\n",
    "print(\"\\nFinal predict time:{}\\nfinal sample\".format(final_predict_time))\n",
    "display(writeData(result,outdir+output_fname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: wrap the above in a function and run for each data set, and plot times, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
